{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24731dc3-d59a-4018-a540-f5fbc3869533",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifier (NBC)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd09ba4-1ee4-4e2a-a52d-9bd17a285842",
   "metadata": {},
   "source": [
    "## Preliminary\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c65414-f348-441b-bbcb-4d0f7efd5652",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "\n",
    "#### Bayes' theorem \n",
    "The conditional possibility of event $A$ given the event $B$ is true $P(A \\mid B)$ can be computed as:\n",
    "\n",
    "$$ P(A \\mid B) = \\frac{P(B \\mid A) \\times P(A)}{P(B)} $$\n",
    "\n",
    "which in the Bayesian term is written as:\n",
    "\n",
    "$$ \\mathrm{Posterior} = \\frac{\\mathrm{Likelihood} \\times \\mathrm{Prior}}{\\mathrm{Evidence}} $$\n",
    "\n",
    "Understand prior and posterior:\n",
    "\n",
    "- **Prior** $P(A)$ is the prior knowledge of the event $A$ *before* knowing anything about event $B$. \n",
    "\n",
    "- **Posterior** $P(A \\mid B)$ is the updated knowledge of the event $A$ *after* knowing something about event $B$. \n",
    "\n",
    "If we think $A$ as a label and $B$ as a set of features:\n",
    "\n",
    "- $P(A \\mid B)$ is the **posterior** probability of a label given a set of features.\n",
    "\n",
    "- $P(B \\mid A)$ is the **likelihood** which is the probability of a set of features given a label.\n",
    "\n",
    "- $P(A)$ is the **prior** probability of a label.\n",
    "\n",
    "- $P(B)$ is the **evidence** probability of a set of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e8aff-2c81-4135-b76e-7a0a079d6a1e",
   "metadata": {},
   "source": [
    "## Statistical estimation\n",
    "---\n",
    "\n",
    "Question: assuming that we have a certain model (distribution) with unknown parameter $\\theta$ and we have observations $\\mathbf{x} = (x_{1}, x_{2}, \\dots, x_{n})$ sampled from the model, how can we have a good estimate of the model parameter $\\theta$? Here we present two methods to answer the above question. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaacfe9-755e-4fb8-9046-3658cf8549f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Maximum Likelihood Estimation (MLE)\n",
    "\n",
    "Let $\\mathbf{x} = (x_{1}, \\dots, x_{n})$ be samples from a model (distribution) with a parameter (or a vector of parameters) $\\theta$. We define the **likelihood** of $\\mathbf{x}$ given $\\theta$ to be the \"probability\" of observing $\\mathbf{x}$ if the true parameter is $\\theta$.\n",
    "\n",
    "$$ L(\\mathbf{x} \\mid \\theta) $$\n",
    "\n",
    "The best parameter $\\theta$ is the one that simply maximizes the likelihood (log-likelihood), which is called **maximum likelihood estimation** (of the model parameter).\n",
    "\n",
    "$$ \\theta_{MLE} = \\arg\\max_{\\theta} L(\\mathbf{x} \\mid \\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6d780-9559-40c6-94ad-c0fa35ead39b",
   "metadata": {},
   "source": [
    "### Maximum A Posteriori Estimation (MAP)\n",
    "\n",
    "Both \"a posteriori\" and \"a priori\" are Latin phrases\n",
    "\n",
    "- \"a posteriori\" (posterior): \"relating to or derived by reasoning from observed facts\" or \"from the later\".\n",
    "\n",
    "- \"a priori\" (prior): \"relating to or derived by reasoning from self-evident propositions\" or \"from the earlier\".\n",
    "\n",
    "Instead of maximizing $P(\\mathbf{x} \\mid \\theta)$ using MLE, we can also maximizing $P(\\theta \\mid \\mathbf{x})$, which is exactly the posterior in Bayes' theorem. Hence the **maximum A Posteriori estimation** (maximizing posterior estimation).\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\theta_{MAP} & = \\arg\\max_{\\theta} P(\\theta \\mid \\mathbf{x}) \\\\\n",
    "& = \\arg\\max_{\\theta} \\frac{L(\\mathbf{x} \\mid \\theta) P(\\theta)}{P(\\mathbf{x})} & \\text{[Bayes' theorem]} \\\\\n",
    "& = \\arg\\max_{\\theta} L(\\mathbf{x} \\mid \\theta) P(\\theta) & \\text{[$P(\\mathbf{x}$) is a fixed value]} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "As we can see, Bayes' theorem turns MAP into the likelihood times the prior. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f847d77-5c32-48db-8541-661a2b06cf6e",
   "metadata": {},
   "source": [
    "### MLE vs MAP\n",
    "\n",
    "Both MLE and MAP are ways to estimate unknown parameters $\\theta$ of a model based on the observed samples $\\mathbf{x}$ from the model. \n",
    "\n",
    "- MLE directly maximizes likelihood $P(\\mathbf{x} \\mid \\theta)$, which is defined as the probability of the observation the samples $\\mathbf{x}$ if the true parameter is $\\theta$. \n",
    "\n",
    "- MAP incorporates the prior knowledge of the parameter $P(\\theta)$ and maximizes the prior times the likelihood. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce13ffa-8807-4994-97ae-633d6b994089",
   "metadata": {},
   "source": [
    "### Independent variables and the log trick\n",
    "\n",
    "If we further assume that random variables $\\mathbf{x} = (x_{1}, \\dots, x_{n})$ are **independent and identically** distributed (i.i.d), the likelihood can be further decomposed:\n",
    "\n",
    "$$ L(\\mathbf{x} \\mid \\theta) = \\prod_{i=1}^{n} P(x_{i} \\mid \\theta) $$\n",
    "\n",
    "Since the probabilities are decimal values, the product of probabilities will often result in a very small values, which will cause problems in real computations. \n",
    "\n",
    "To simplify the computation process, we usually use **log-likelihood**, which is just to take the natural logarithm of likelihood, since logarithm turns a product to a sum. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta_{MLE} \n",
    "& = \\arg\\max_{\\theta} L(\\mathbf{x} \\mid \\theta) \\\\\n",
    "& = \\arg\\max_{\\theta} \\log \\prod_{i=1}^{n} P(x_{i} \\mid \\theta) \\\\\n",
    "& = \\arg\\max_{\\theta} \\sum_{i=1}^{n} \\log P(x_{i} \\mid \\theta) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Similar to MLE, we also maximize $\\log$ form of MAP to simplify the process, \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\theta_{MAP} \n",
    "& = \\arg\\max_{\\theta} L(\\mathbf{x} \\mid \\theta) P(\\theta) \\\\ \n",
    "& = \\arg\\max_{\\theta} \\log L(\\mathbf{x} \\mid \\theta) P(\\theta) \\\\\n",
    "& = \\arg\\max_{\\theta} \\log L(\\mathbf{x} \\mid \\theta) + \\log P(\\theta) \\\\\n",
    "& = \\arg\\max_{\\theta} \\sum_{i=1}^{n} \\log P(x_{i} \\mid \\theta) + \\log P(\\theta)  \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c651905-f440-4f1f-ab43-f0ed3329e45d",
   "metadata": {},
   "source": [
    "## Naive Bayes as a classifier\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad0eabd-2fbc-41c1-a5f7-523aed5a3aa4",
   "metadata": {},
   "source": [
    "### NBC as MAP\n",
    "\n",
    "Naive Bayes is a classifier that selects the label $\\hat{y}$ from all possible labels $y \\in Y$ that has maximum conditional probability given the instance $\\mathbf{x} \\in \\mathbb{R}^{d}$\n",
    "\n",
    "$$ \\hat{y} = \\arg\\max_{y \\in Y} P(y \\mid \\mathbf{x}) $$\n",
    "\n",
    "The above conditional probability can be seen as a Maximum A Posteriori Estimation problem if:\n",
    "\n",
    "1. we consider $y$ as the unknown parameter of a model. \n",
    "\n",
    "1. we assume that each feature is independent from each other **(naive conditional independence assumption)**. \n",
    "\n",
    "Following the formulation of MAP,\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "\\hat{y} & = \\arg\\max_{y \\in Y} P(y \\mid \\mathbf{x}) \\\\\n",
    "& = \\arg\\max_{y \\in Y} \\sum_{j=1}^{d} \\log P(x_{j} \\mid y) + \\log P(y) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where $x_{j}$ is the value of $j$th feature in the instance $\\mathbf{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9620bb2a-7c76-47ba-96a6-28d805802b1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Learn a NBC from the training set\n",
    "\n",
    "We can learn both $\\sum_{j=1}^{d} \\log P(x_{j} \\mid y)$ and $\\log P(y)$ from the training set. Suppose we have a training set with instances $\\mathbf{X} \\in \\mathbb{R}^{n \\times d}$ and labels $\\mathbf{y} \\in \\mathbb{Z}^{n}$:\n",
    "\n",
    "As a classification problem, $P(y)$ can be easily calculated by counting the number of instances with label $y$:\n",
    "\n",
    "$$ P(y) = \\frac{\\text{# instances with label $y$}}{\\text{# all instances}} = \\frac{\\sum_{i}^{n} \\mathbb{1}[\\mathbf{y}_{i} = y]}{n} $$\n",
    "\n",
    "However, $P(x_{j} \\mid y)$ is more difficult to evaluate and depends on the type of the $j$th feature.\n",
    "\n",
    "- If the $j$th feature is a categorical feature, the likelihood $P(x_{j} \\mid y)$ can also be easily calculated by counting the number of instances with label $y$ and value $x_{j}$ for the $j$th feature:\n",
    "\n",
    "    $$ P(x_{j} \\mid y) = \\frac{\\text{# instances with label $y$ and value $x_{j}$ for the $j$th feature}}{\\text{# instances with label $y$}} = \\frac{\\sum_{i}^{n} \\mathbb{1}[\\mathbf{y}_{i} = y, \\mathbf{X}_{i, j}=x_{j}]}{\\sum_{i}^{n} \\mathbb{1}[\\mathbf{y}_{i} = y]} $$\n",
    "    \n",
    "    However, if for some reason there is no instance in the training set that has value $x_{j}$ for the $j$th feature, $P(x_{j} \\mid y)$ will be 0 and $\\log P(x_{j} \\mid y) = -\\inf$, which is problem since then $P(\\mathbf{x} \\mid y) = -\\inf$ and thus label $y$ will never will selected. This problem can be solved by including Laplace smoothing with a smoothing parameter $\\alpha$:\n",
    "    \n",
    "    $$ P(x_{j} \\mid y) = \\frac{\\sum_{i}^{n} \\mathbb{1}[\\mathbf{y}_{i} = y, \\mathbf{X}_{i, j}=x_{j}] + \\alpha}{\\sum_{i}^{n} \\mathbb{1}[\\mathbf{y}_{i} = y] + \\alpha \\lvert X_{*, j} \\rvert} $$\n",
    "    \n",
    "    where $\\lvert X_{*, j} \\rvert$ is the number of unique values that  the $j$th feature can take.\n",
    "    \n",
    "- If the $j$th feature is a continuous feature, we may need to assume a the likelihood follows a specific distribution. If we select Gaussian distribution:\n",
    "\n",
    "    $$ P(x_{j} \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma_{j, y}^{2}}}\\exp({-\\frac{(x_{j} - \\mu_{j, y})^{2}}{2\\sigma_{j, y}^{2}}}) $$\n",
    "    \n",
    "    where $\\mu_{j, y}$ is the mean of the values of the $j$th feature in the instances with label $y$\n",
    "    \n",
    "    $$ \\mu_{j, y} = \\frac{\\sum_{i}^{n} \\mathbf{X}_{i, j} \\mathbb{1}[\\mathbf{y}_{i} = y]}{\\sum_{i}^{n} \\mathbb{1}[\\mathbf{y}_{i} = y]} $$\n",
    "    \n",
    "    and  $\\sigma_{j, y}$ is the standard deviation of the values of the $j$th feature in the instances with label $y$\n",
    "    \n",
    "    $$ \\sigma_{j, y} = \\sqrt{\\frac{\\sum_{i}^{n} (\\mathbf{X}_{i, j} - \\mu_{i, j})^{2} \\mathbb{1}[\\mathbf{y}_{i} = y]}{\\sum_{i}^{n} \\mathbb{1}[\\mathbf{y}_{i} = y]}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe00425-c5ed-4b0d-831c-c89d1c8fe365",
   "metadata": {
    "tags": []
   },
   "source": [
    "## References\n",
    "---\n",
    "\n",
    "1. https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "1. Charter 7 in http://www.alextsun.com/files/Prob_Stat_for_CS_Book.pdf\n",
    "1. https://www.cs.cmu.edu/~epxing/Class/10701-10s/Lecture/lecture5.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
