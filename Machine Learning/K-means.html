<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Joeyonngâ€™s Notebook - 41&nbsp; K-means</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../Machine Learning/7_Decision_Tree.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css" rel="stylesheet">

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="https://joeyonng.github.io/joeyonng/">
    <span class="navbar-title">Joeyonng</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../index.html" rel="" target="" aria-current="page">
 <span class="menu-text">Notebook</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://joeyonng.github.io/joeyonng/Notes/" rel="" target="">
 <span class="menu-text">Pages</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://joeyonng.github.io/joeyonng/" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://joeyonng.github.io/joeyonng-backyard/" rel="" target="">
 <span class="menu-text">Backyard</span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../Machine Learning/1_Linear_Discriminant.html">Machine Learning</a></li><li class="breadcrumb-item"><a href="../Machine Learning/K-means.html"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">K-means</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../notations.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Notations and Facts</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false">
 <span class="menu-text">Linear Algebra</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/01_Fields_and_Spaces.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Fields and Spaces</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/02_Vectors_and_Matrices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Vectors and Matrices</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/03_Span_and_Linear_Independence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Span and Linear Independence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/04_Basis_and_Dimension.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Basis and Dimension</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/05_Linear_Map_and_Rank.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Linear Map and Rank</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/06_Inner_Product_and_Norm.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Inner Product and Norm</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/07_Orthogonality_and_Orthogonal_Matrix.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Orthogonality and Orthogonal Matrix</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/08_Complementary_Subspaces_and_Projection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Complementary Subspaces and Projection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/09_Orthogonal_Complement_and_Decomposition.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Orthogonal Complement and Decomposition</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/10_Singular_Value_Decomposition_and_Pseudoinverse.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">SVD and Pseudoinverse</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/11_Orthogonal_and_Affine_Projection.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Orthogonal and Affine Projection</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/12_Determinants_and_Eigensystems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Determinants and Eigensystems</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/13_Similarity_and_Diagonalization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Similarity and Diagonalization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Linear Algebra/14_Normal_and_Positive_Definite_Matrices.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Normal and Positive Definite Matrices</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false">
 <span class="menu-text">Probability and Statistics</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Probability and Statistics/01_Probability.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Probability</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Probability and Statistics/02_Random_Variables.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Random Variables</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Probability and Statistics/03_Expectation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Expectation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Probability and Statistics/04_Common_Distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Common Distributions</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Probability and Statistics/05_Moment_Generating_Functions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Moment Generating Function</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Probability and Statistics/06_Concentration_Inequalities_I.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Concentration Inequalities I</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Probability and Statistics/07_Convergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Convergence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Probability and Statistics/08_Limit_Theorems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Limit Theorems</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Probability and Statistics/09_Maximum_Likelihood_Estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Maximum Likelihood Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Probability and Statistics/10_Bayesian_Estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">Bayesian Estimation</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Probability and Statistics/11_Expectation_Maximization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Expectation-maximization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Probability and Statistics/12_Concentration_Inequalities2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Concentration Inequalities II</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false">
 <span class="menu-text">Learning Theory</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Learning Theory/1_Statistical_Learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Statistical Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Learning Theory/2_Bayesian_Classifier.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Bayesian Classifier</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Learning Theory/3_Effective_Class_Size.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">29</span>&nbsp; <span class="chapter-title">Effective Class Size</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Learning Theory/4_Empirical_Risk_Minimization.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">30</span>&nbsp; <span class="chapter-title">Empirical Risk Minimization</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Learning Theory/5_Uniform_Convergence.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">31</span>&nbsp; <span class="chapter-title">Uniform Convergence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Learning Theory/6_PAC_Learning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">32</span>&nbsp; <span class="chapter-title">PAC Learning</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Learning Theory/7_Rademacher_Complexity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">33</span>&nbsp; <span class="chapter-title">Rademacher Complexity</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true">
 <span class="menu-text">Machine Learning</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Machine Learning/1_Linear_Discriminant.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">34</span>&nbsp; <span class="chapter-title">Linear Discriminant</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Machine Learning/2_Perceptron.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">35</span>&nbsp; <span class="chapter-title">Perceptron</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Machine Learning/3_Logistic_Regression.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">36</span>&nbsp; <span class="chapter-title">Logistic Regression</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Machine Learning/4_Multi_Layer_Perceptron.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">37</span>&nbsp; <span class="chapter-title">Multi-layer Perceptron</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Machine Learning/5_Boosting.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">38</span>&nbsp; <span class="chapter-title">Boosting</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Machine Learning/6_Support_Vector_Machine.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">39</span>&nbsp; <span class="chapter-title">Support Vector Machine</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Machine Learning/7_Decision_Tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Decision Tree</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../Machine Learning/K-means.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">K-means</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content column-page-right" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">41</span>&nbsp; <span class="chapter-title">K-means</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p><em>Updated 01-12-2023 (First commited 02-27-2022)</em></p>
<hr>
<ol type="1">
<li>K-means is used to cluster unlabeled instances in dataset into K groups that are defined by their centroids. The points in the same group can be further labeled or analyzed.</li>
<li>We first randomly choose K centroids in the space. Then we cluster each data point to its nearest centroids and distance is calculated using sum of the square of the difference. After all data points have been assigned to a cluster, we recompute the centroids of the cluster by taking the average of all the data points that belong to that cluster. Then we cluster the data points again based on the new centroids and we repeat process until centroids donâ€™t really change.</li>
<li>K-means is proved to find local minimum instead of global minimum. Thus the initialization of the centroids do matter to the outcome.</li>
</ol>
<section id="preliminary" class="level2">
<h2 class="anchored" data-anchor-id="preliminary">Preliminary</h2>
<hr>
<section id="statistics" class="level3">
<h3 class="anchored" data-anchor-id="statistics">Statistics</h3>
<section id="estimator" class="level4">
<h4 class="anchored" data-anchor-id="estimator">Estimator</h4>
<p>In statistics, an estimator is a <strong>function that takes as inputs a set of observations</strong> sampled from an unknown probability distribution <span class="math inline">P_{\theta}(X)</span> with the true parameter <span class="math inline">\theta</span> and <strong>outputs the best guess of the parameter</strong> <span class="math inline">\hat{\theta}</span> of <span class="math inline">P_{\theta}(X)</span>.</p>
<ul>
<li>An estimator is also a random variable.</li>
</ul>
</section>
<section id="bias" class="level4">
<h4 class="anchored" data-anchor-id="bias">Bias</h4>
<p>The bias of an estimator measures <strong>whether the expectation of the estimator is the same as the true parameter</strong>. Let <span class="math inline">\hat{\theta}</span> be the output of an estimator for <span class="math inline">\theta</span>. The bias of <span class="math inline">\hat{\theta}</span> as an estimator for <span class="math inline">\theta</span> is</p>
<p><span class="math display"> \operatorname{Bias}(\hat{\theta}, \theta) = \mathbb{E}[\hat{\theta}] - \theta </span></p>
<ul>
<li><span class="math inline">\operatorname{Bias}(\hat{\theta}, \theta) = 0</span>, then we say <span class="math inline">\hat{\theta}</span> is an <strong>unbiased</strong> estimator of <span class="math inline">\theta</span>.</li>
<li><span class="math inline">\operatorname{Bias}(\hat{\theta}, \theta) &gt; 0</span>, <span class="math inline">\hat{\theta}</span> typically <strong>overestimates</strong> <span class="math inline">\theta</span>.</li>
<li><span class="math inline">\operatorname{Bias}(\hat{\theta}, \theta) &lt; 0</span>, <span class="math inline">\hat{\theta}</span> typically <strong>underestimates</strong> <span class="math inline">\theta</span>.</li>
</ul>
</section>
<section id="variance-of-an-estimator" class="level4">
<h4 class="anchored" data-anchor-id="variance-of-an-estimator">Variance (of an estimator)</h4>
<p>The variance of an estimator measures the degree to which the <strong>estimated parameters vary depending on the sampled observations</strong>. Let <span class="math inline">\hat{\theta}</span> be the output of an estimator for <span class="math inline">\theta</span>. The variance of <span class="math inline">\hat{\theta}</span> as an estimator is</p>
<p><span class="math display"> \operatorname{Var}(\hat{\theta}) = \mathbb{E}[(\hat{\theta} - \mathbb{E}[\hat{\theta}])^{2}] </span></p>
</section>
<section id="mean-squared-error" class="level4">
<h4 class="anchored" data-anchor-id="mean-squared-error">Mean squared error</h4>
<p>In statistics, the mean squared error (MSE) is a risk (loss) function measures the <strong>difference between an estimator <span class="math inline">\hat{\theta}</span> with the true parameter <span class="math inline">\theta</span></strong>.</p>
<p><span class="math display"> \operatorname{MSE}(\hat{\theta}, \theta) = \mathbb{E}[(\hat{\theta} - \theta)^{2}] </span></p>
<p>If the estimator <span class="math inline">\hat{\boldsymbol{\theta}}</span> and the true parameter <span class="math inline">\boldsymbol{\theta}</span> are vectors,</p>
<p><span class="math display"> \operatorname{MSE}(\hat{\boldsymbol{\theta}}, \boldsymbol{\theta}) = \mathbb{E}[\lVert \hat{\boldsymbol{\theta}} - \boldsymbol{\theta} \rVert^{2}] </span></p>
</section>
<section id="bias-variance-decomposition" class="level4">
<h4 class="anchored" data-anchor-id="bias-variance-decomposition">Bias-variance decomposition</h4>
<p>A risk (loss) function can be often decomposed into a <strong>bias, a variance and a noise term</strong>. Here we take MSE as an example and expand it into a bias and variance term (noise is omitted).</p>
<p><span class="math display"> \operatorname{MSE}(\hat{\boldsymbol{\theta}}, \boldsymbol{\theta}) = \operatorname{Var}(\hat{\boldsymbol{\theta}}) + \operatorname{Bias}(\hat{\boldsymbol{\theta}}, \boldsymbol{\theta})^{2} </span></p>
<p>:::{admonition} Proof :class: dropdown</p>
<p><span class="math display">
\begin{align}
\operatorname{MSE}(\hat{\boldsymbol{\theta}}, \boldsymbol{\theta}) &amp; = \mathbb{E}[ \lVert \hat{\boldsymbol{\theta}} - \boldsymbol{\theta} \rVert^{2} ] \\
&amp; = \mathbb{E}[ \lVert \hat{\boldsymbol{\theta}} - \mathbb{E}[\hat{\boldsymbol{\theta}}] + \mathbb{E}[\hat{\boldsymbol{\theta}}] - \boldsymbol{\theta} \rVert^{2}] &amp; [\text{add and subtract } \mathbb{E}[\hat{\boldsymbol{\theta}}] ] \\
&amp; = \mathbb{E}[ \lVert \hat{\boldsymbol{\theta}} - \mathbb{E}[\hat{\boldsymbol{\theta}}] \rVert^{2} + 2 \lVert \hat{\boldsymbol{\theta}} - \mathbb{E}[\hat{\boldsymbol{\theta}}] \rVert \lVert \mathbb{E}[\hat{\boldsymbol{\theta}}] - \boldsymbol{\theta} \rVert + \lVert \mathbb{E}[\hat{\boldsymbol{\theta}}] - \boldsymbol{\theta} \rVert^{2} ] &amp; [(a + b)^{2} = a^{2} + 2ab + b^{2}] \\
&amp; = \mathbb{E}[ \lVert \hat{\boldsymbol{\theta}} - \mathbb{E}[\hat{\boldsymbol{\theta}}] \rVert^{2} ] + \mathbb{E}[ 2 \lVert \hat{\boldsymbol{\theta}} - \mathbb{E}[\hat{\boldsymbol{\theta}}] \rVert \lVert \mathbb{E}[\hat{\boldsymbol{\theta}}] - \boldsymbol{\theta} \rVert ] + \mathbb{E}[ \lVert \mathbb{E}[\hat{\boldsymbol{\theta}}] - \boldsymbol{\theta} \rVert^{2} ] &amp; [\text{Linearity of Expectation}] \\
&amp; = \operatorname{Var}(\hat{\boldsymbol{\theta}}) + 2\mathbb{E}[ \lVert \hat{\boldsymbol{\theta}} - \mathbb{E}[\hat{\boldsymbol{\theta}}] \rVert] \mathbb{E}[ \lVert \mathbb{E}[\hat{\boldsymbol{\theta}}] - \boldsymbol{\theta} \rVert ] + \mathbb{E}[ \operatorname{Bias}(\hat{\boldsymbol{\theta}}, \boldsymbol{\theta})^{2} ] \\
&amp; = \operatorname{Var}(\hat{\boldsymbol{\theta}}) + \operatorname{Bias}(\hat{\boldsymbol{\theta}}, \boldsymbol{\theta})^{2} &amp; [\mathbb{E}[ \lVert \hat{\boldsymbol{\theta}} - \mathbb{E}[\hat{\boldsymbol{\theta}}] \rVert] = \lVert \mathbb{E}[\hat{\boldsymbol{\theta}}] - \mathbb{E}[\hat{\boldsymbol{\theta}}] \rVert = 0] \\
\end{align}
</span></p>
<p>:::</p>
</section>
</section>
</section>
<section id="problem-formulation" class="level2">
<h2 class="anchored" data-anchor-id="problem-formulation">Problem formulation</h2>
<hr>
<ul>
<li><p>K-means clustering algorithm is a unsupervised learning algorithm that aims to <strong>cluster similar instances into the same group</strong>.</p></li>
<li><p>The input to the algorithm is <span class="math inline">n</span> instances <span class="math inline">\mathbf{x}_{1}, \mathbf{x}_{2}, \dots, \mathbf{x}_{n} \in \mathbb{R}^{d}</span> <strong>without labels</strong> and the output of the algorithm is <span class="math inline">k</span> centroids <span class="math inline">\mathbf{u}_{1}, \mathbf{u}_{2}, \dots, \mathbf{u}_{k} \in \mathbb{R}^{d}</span>, where <span class="math inline">k</span> is a hyperparameter used to control the number of centroids desired.</p></li>
<li><p>The goal of K-means clustering is to find the best <span class="math inline">k</span> centroids that minimizes a loss function (often <strong>MSE loss</strong> of the <strong><span class="math inline">L_{2}</span> norm or euclidean distance</strong> of the difference vector) that captures the overall distances between the instances and the centroids assigned.</p>
<p><span class="math display"> \operatorname{loss}(\mathbf{u}_{1}, \dots, \mathbf{u}_{k}) = \sum_{i = 1}^{n} \lVert \mathbf{x}_{i} - \mathbf{u}_{x_{i}} \rVert^{2} </span></p>
<p>where <span class="math inline">\mathbf{u}_{x_{i}}</span> is the centroid that instance <span class="math inline">\mathbf{x}_{i}</span> is assigned to.</p></li>
<li><p>Another way to write the loss function is to consider the distances between each centroid and the instances in the cluster that the centroid represents. The benefit of this formulation is that the clusters that the centroids represent are separated as variables, which is easier to do algorithm analyzing.</p>
<p><span class="math display"> \operatorname{loss}(\mathbf{u}_{1}, \dots, \mathbf{u}_{k}, C_{\mathbf{u}_{1}}, \dots, C_{\mathbf{u}_{k}}) = \sum_{i = 1}^{k} \sum_{\mathbf{x} \in C_{\mathbf{u}_{i}}} \lVert \mathbf{x} - \mathbf{u}_{i} \rVert^{2} </span></p>
<p>where <span class="math inline">C_{\mathbf{u}_{i}}</span> is the cluster that centroid <span class="math inline">\mathbf{u}_{i}</span> represents.</p></li>
</ul>
</section>
<section id="k-means-using-lloyds-algorithm" class="level2">
<h2 class="anchored" data-anchor-id="k-means-using-lloyds-algorithm">K-means using Lloydâ€™s algorithm</h2>
<hr>
<section id="algorithm" class="level3">
<h3 class="anchored" data-anchor-id="algorithm">Algorithm</h3>
<blockquote class="blockquote">
<p><strong>Function</strong>: K-means<br>
<strong>Input</strong>: a set of instances <span class="math inline">\mathbf{x}_{1}, \mathbf{x}_{2}, \dots, \mathbf{x}_{n}</span> and a hyperparameter <span class="math inline">k</span>.<br>
<strong>Output</strong>: a set of centroids <span class="math inline">\mathbf{u}_{1}, \mathbf{u}_{2}, \dots, \mathbf{u}_{k}</span>. 1. Initialize cluster centroids <span class="math inline">\mathbf{u}_{1}, \mathbf{u}_{2}, \dots, \mathbf{u}_{k}</span> by randomly drawing <span class="math inline">k</span> instances as the centroids. 2. Repeat until convergence or a fixed number of iterations: 1. <strong>Assignment step</strong>: get the nearest centroid <span class="math inline">\mathbf{c}_{i}</span> for each instance <span class="math inline">\mathbf{x}_{i}</span>:</p>
<pre><code>    $$ \mathbf{c}_{i} = \arg \min_{j} \lVert \mathbf{x}_{i} - \mathbf{u}_{j} \rVert^{2} $$

2. **Refitting step**: update each centroid based on the instances in its cluster:

    $$ \mathbf{u}_{j} = \frac{\sum_{i}^{m} \mathbb{1}_{\mathbf{c}_i = j} \mathbf{x}_{i}}{\sum_{i}^{m} \mathbb{1}_{\mathbf{c}_{i} = j}} $$</code></pre>
</blockquote>
</section>
<section id="convergence-of-lloyds-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="convergence-of-lloyds-algorithm">Convergence of Lloydâ€™s algorithm</h3>
<p>K-means solved using Lloydâ€™s algorithm is guaranteed to converge to a local minimum because: - The loss value is guaranteed to be smaller or stay the same in the assignment step because each instance <span class="math inline">\mathbf{x}_{i}</span> gets the nearest centroid.</p>
<pre><code>$$ \operatorname{loss}( \mathbf{u}_{1}, \dots, \mathbf{u}_{k}, (C_{\mathbf{u}_{1}}, \dots, C_{\mathbf{u}_{k}})^{t + 1} ) \leq \operatorname{loss}( \mathbf{u}_{1}, \dots, \mathbf{u}_{k}, (C_{\mathbf{u}_{1}}, \dots, C_{\mathbf{u}_{k}})^{t} ) $$
    </code></pre>
<ul>
<li><p>The loss value is guaranteed to be smaller or stay the same in the refitting step.</p>
<p><span class="math display"> \operatorname{loss}( (\mathbf{u}_{1}, \dots, \mathbf{u}_{k})^{t + 1}, (C_{\mathbf{u}_{1}}, \dots, C_{\mathbf{u}_{k}})^{t + 1} ) \leq \operatorname{loss}( (\mathbf{u}_{1}, \dots, \mathbf{u}_{k})^{t}, (C_{\mathbf{u}_{1}}, \dots, C_{\mathbf{u}_{k}})^{t + 1} ) </span></p>
<p>To see why this is true, consider a single centroid-cluster pair <span class="math inline">\mathbf{u}</span> and <span class="math inline">C_{\mathbf{u}}</span>, for all instances <span class="math inline">\mathbf{x}_{1}, \mathbf{x}_{2}, \dots, \mathbf{x}_{n}</span> that belongs to the cluster <span class="math inline">C_{\mathbf{u}}</span>, the loss function <span class="math inline">\operatorname{loss}(\mathbf{u}, C_{\mathbf{u}})</span> will be minimized when <span class="math inline">\mathbf{u}</span> is the average of the instances in <span class="math inline">C_{\mathbf{u}}</span>:</p>
<p><span class="math display"> \boldsymbol{\mu} = \frac{1}{n} \sum_{\mathbf{x} \in C_{\mathbf{u}}} \mathbf{x}_{i} = \arg \min_{\mathbf{u} \in \mathbb{R}^{d}} \sum_{\mathbf{x} \in C_{\mathbf{u}}} \lVert \mathbf{x} - \mathbf{u} \rVert^{2} = \arg \min_{\mathbf{u} \in \mathbb{R}^{d}} \operatorname{loss}(\mathbf{u}, C_{\mathbf{u}}) </span></p>
<p>because of the equation below derived from the bias-variance decomposition of MSE function:</p>
<p><span class="math display"> \operatorname{loss}(\mathbf{u}, C_{\mathbf{u}}) = \operatorname{loss}(\mathbf{\boldsymbol{\mu}}, C_{\mathbf{\mathbf{u}}}) + n \lVert \boldsymbol{\mu} - \mathbf{u} \rVert </span></p>
<p>where <span class="math inline">n</span> is the number of instances in the cluster <span class="math inline">C_{\mathbf{u}}</span>.</p>
<p>:::{admonition} Proof :class: dropdown</p>
<p><span class="math display">
  \begin{align}
  \operatorname{loss}(\mathbf{u}, C_{\mathbf{u}}) &amp; = \operatorname{loss}(\boldsymbol{\mu}, C_{\mathbf{u}}) + n\lVert \boldsymbol{\mu} - \mathbf{u} \rVert^{2} \\
  &amp; = \sum_{\mathbf{x} \in C_{\mathbf{u}}} \lVert \mathbf{x} - \boldsymbol{\mu} \rVert^{2} + n\lVert \boldsymbol{\mu} - \mathbf{u} \rVert^{2} \\
  &amp; = \sum_{\mathbf{x} \in C_{\mathbf{u}}} \left( \lVert \mathbf{x} \rVert^{2} - 2\lVert \mathbf{x} \rVert \lVert \boldsymbol{\mu} \rVert + \lVert \boldsymbol{\mu} \rVert^{2} \right) + n\left( \lVert \boldsymbol{\mu} \rVert^{2} - 2 \lVert \boldsymbol{\mu} \rVert \lVert \mathbf{u} \rVert + \lVert \mathbf{u} \rVert^{2} \right) \\
  &amp; = \sum_{\mathbf{x} \in C_{\mathbf{u}}} \left( \lVert \mathbf{x} \rVert^{2} - 2\lVert \mathbf{x} \rVert \lVert \frac{S}{n} \rVert + \lVert \frac{S}{n} \rVert^{2} \right) + n\left( \lVert \frac{S}{n} \rVert^{2} - 2 \lVert \boldsymbol{\mu} \rVert \lVert \mathbf{u} \rVert + \lVert \mathbf{u} \rVert^{2} \right) &amp; \left[ \text{replace some } \boldsymbol{\mu} \text{ with } \frac{S}{n} \text{ where } S = \sum_{\mathbf{x} \in C_{\mathbf{u}}} \mathbf{x} \right] \\
  &amp; = \sum_{\mathbf{x} \in C_{\mathbf{u}}} \lVert \mathbf{x} \rVert^{2} - \sum_{\mathbf{x} \in C_{\mathbf{u}}} 2\lVert \mathbf{x} \rVert \lVert \frac{S}{n} \rVert + \sum_{\mathbf{x} \in C_{\mathbf{u}}} \lVert \frac{S}{n} \rVert^{2} + n\lVert \frac{S}{n} \rVert^{2} - 2n\lVert \boldsymbol{\mu} \rVert \lVert \mathbf{u} \rVert + n\lVert \mathbf{u} \rVert^{2} \\
  &amp; = \sum_{\mathbf{x} \in C_{\mathbf{u}}} \lVert \mathbf{x} \rVert^{2} - 2 \lVert S \rVert \lVert \frac{S}{n} \rVert + n\lVert \frac{S}{n} \rVert^{2} + n\lVert \frac{S}{n} \rVert^{2} - 2n\lVert \boldsymbol{\mu} \rVert \lVert \mathbf{u} \rVert + n\lVert \mathbf{u} \rVert^{2} &amp; \left[ \sum_{\mathbf{x} \in C_{\mathbf{u}}} \lVert x \rVert = \lVert S \rVert \text{ and } \sum_{\mathbf{x} \in C_{\mathbf{u}}} 1 = n \right] \\
  &amp; = \sum_{\mathbf{x} \in C_{\mathbf{u}}} \lVert \mathbf{x} \rVert^{2} - 2n\lVert \boldsymbol{\mu} \rVert \lVert \mathbf{u} \rVert + n\lVert \mathbf{u} \rVert^{2} &amp; \left[ \lVert S \rVert \lVert \frac{S}{n} \rVert = n\lVert \frac{S}{n} \rVert^{2}  \right] \\
  &amp; = \sum_{\mathbf{x} \in C_{\mathbf{u}}} ( \lVert \mathbf{x} \rVert^{2} - 2\lVert \boldsymbol{\mu} \rVert \lVert \mathbf{u} \rVert + \lVert \mathbf{u} \rVert^{2} ) \\
  &amp; = \sum_{\mathbf{x} \in C_{\mathbf{u}}} \lVert \mathbf{x} - \mathbf{u} \rVert^{2} \\
  \end{align}
  </span></p>
<p>Since <span class="math inline">\lvert C_{\mathbf{\mathbf{u}}} \rvert \cdot \lVert \boldsymbol{\mu} - \mathbf{u} \rVert</span> is always positive,</p>
<p><span class="math display"> \operatorname{loss}(\boldsymbol{\mu}, C_{\mathbf{u}}) \leq \operatorname{loss}(\mathbf{\mathbf{u}}, C_{\mathbf{\mathbf{u}}}) </span></p>
<p>:::</p></li>
</ul>
</section>
</section>
<section id="the-k-means-initializer" class="level2">
<h2 class="anchored" data-anchor-id="the-k-means-initializer">The K-means++ initializer</h2>
<hr>
<p>Although the default behavior of the K-means algorithm is to initialize the centroids randomly, the quality of the final solution depends heavily on the initialization because K-means is only guaranteed to converge to a local point.</p>
<p>The K-means++ initializer is a special way of initializing the centroids so that - the convergence of K-means is faster, - the final loss is bounded (the quality of the final solution wonâ€™t be very bad).</p>
<blockquote class="blockquote">
<ol type="1">
<li>Pick an instance <span class="math inline">\mathbf{x}</span> uniformly at random and set <span class="math inline">T \gets \{\mathbf{x}\}</span></li>
<li>While <span class="math inline">\lvert T \rvert &lt; k</span>:
<ol type="1">
<li><p>Pick an instance <span class="math inline">\mathbf{x}</span> at random, with probability proportional to</p>
<p><span class="math display"> \operatorname{cost}(\mathbf{x}, T) = \min_{\mathbf{u} \in T} \lVert \mathbf{x} - \mathbf{u} \rVert^{2} </span></p></li>
<li><p>Add <span class="math inline">\mathbf{x}</span> to <span class="math inline">T</span>.</p></li>
</ol></li>
</ol>
</blockquote>
</section>
<section id="reference" class="level2">
<h2 class="anchored" data-anchor-id="reference">Reference</h2>
<hr>
<ol type="1">
<li>https://stanford.edu/~cpiech/cs221/handouts/kmeans.html</li>
<li>https://cseweb.ucsd.edu/~dasgupta/291-geom/kmeans.pdf</li>
</ol>
</section>
<section id="implementation" class="level2">
<h2 class="anchored" data-anchor-id="implementation">Implementation</h2>
<hr>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co">#https://takoscribe.com/2020/12/29/kmeans-clustering-with-pytorch/</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> functools</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tqdm</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.datasets <span class="im">import</span> make_blobs</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> GradientKMeans(nn.Module):</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_centroids, n_epochs, batch_size, lr<span class="op">=</span><span class="fl">1e-2</span>):</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_centroids <span class="op">=</span> num_centroids</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_epochs <span class="op">=</span> n_epochs</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_size <span class="op">=</span> batch_size</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.lr <span class="op">=</span> lr</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _initialize(<span class="va">self</span>, x):</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>        assignment <span class="op">=</span> [i <span class="op">%</span> <span class="va">self</span>.num_centroids <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(x.size(<span class="dv">0</span>))]</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>        random_indices <span class="op">=</span> torch.randperm(<span class="bu">len</span>(assignment))</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>        random_assignment <span class="op">=</span> torch.LongTensor(assignment)[random_indices]</span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_centroids):</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.centroids.data[i] <span class="op">=</span> x[random_assignment <span class="op">==</span> i].mean(<span class="dv">0</span>)</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> _assign(<span class="va">self</span>, x):</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>        indices <span class="op">=</span> ((x[:,<span class="va">None</span>] <span class="op">-</span> <span class="va">self</span>.centroids) <span class="op">**</span> <span class="dv">2</span>).mean(<span class="dv">2</span>).argmin(<span class="dv">1</span>)</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> indices</span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>._assign(x)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X):</span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.centroids <span class="op">=</span> nn.Parameter(torch.zeros(<span class="va">self</span>.num_centroids, X.shape[<span class="dv">1</span>]))</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.optimizer <span class="op">=</span> torch.optim.Adam(<span class="va">self</span>.parameters(), lr<span class="op">=</span><span class="va">self</span>.lr)</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.loss <span class="op">=</span> nn.MSELoss()</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>        centroids_init <span class="op">=</span> <span class="va">False</span></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>        cost_window <span class="op">=</span> <span class="dv">25</span></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>        costs <span class="op">=</span> []</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>        X_t <span class="op">=</span> torch.utils.data.TensorDataset(torch.Tensor(X), torch.zeros((X.shape[<span class="dv">0</span>], )))</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>        iterator <span class="op">=</span> torch.utils.data.DataLoader(X_t, batch_size<span class="op">=</span><span class="va">self</span>.batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.n_epochs):</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> tqdm.tqdm(total<span class="op">=</span><span class="bu">len</span>(X) <span class="op">//</span> <span class="va">self</span>.batch_size) <span class="im">as</span> progress_bar:</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> x, _ <span class="kw">in</span> iterator:</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>                    <span class="cf">if</span> <span class="kw">not</span> centroids_init: </span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>                        <span class="va">self</span>._initialize(x)</span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a>                        centroids_init <span class="op">=</span> <span class="va">True</span></span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a>                    assignment <span class="op">=</span> <span class="va">self</span>._assign(x)</span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.optimizer.zero_grad()</span>
<span id="cb3-57"><a href="#cb3-57" aria-hidden="true" tabindex="-1"></a>                    means <span class="op">=</span> <span class="va">self</span>.centroids[assignment]</span>
<span id="cb3-58"><a href="#cb3-58" aria-hidden="true" tabindex="-1"></a>                    cur_cost <span class="op">=</span> <span class="va">self</span>.loss(x, means)</span>
<span id="cb3-59"><a href="#cb3-59" aria-hidden="true" tabindex="-1"></a>                    cur_cost.backward()</span>
<span id="cb3-60"><a href="#cb3-60" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.optimizer.step()</span>
<span id="cb3-61"><a href="#cb3-61" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb3-62"><a href="#cb3-62" aria-hidden="true" tabindex="-1"></a>                    costs.append(cur_cost.item())</span>
<span id="cb3-63"><a href="#cb3-63" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb3-64"><a href="#cb3-64" aria-hidden="true" tabindex="-1"></a>                    progress_bar.set_postfix({</span>
<span id="cb3-65"><a href="#cb3-65" aria-hidden="true" tabindex="-1"></a>                        <span class="st">'KMeans'</span>: <span class="bu">float</span>(functools.<span class="bu">reduce</span>(<span class="kw">lambda</span> x, y: x <span class="op">+</span> y, costs[<span class="op">-</span>cost_window:])) <span class="op">/</span>  <span class="bu">len</span>(costs[<span class="op">-</span>cost_window:])</span>
<span id="cb3-66"><a href="#cb3-66" aria-hidden="true" tabindex="-1"></a>                    })</span>
<span id="cb3-67"><a href="#cb3-67" aria-hidden="true" tabindex="-1"></a>                    progress_bar.update(<span class="dv">1</span>) <span class="co"># 1 step</span></span>
<span id="cb3-68"><a href="#cb3-68" aria-hidden="true" tabindex="-1"></a>                    </span>
<span id="cb3-69"><a href="#cb3-69" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb3-70"><a href="#cb3-70" aria-hidden="true" tabindex="-1"></a>        Y <span class="op">=</span> <span class="va">self</span>(torch.Tensor(X))</span>
<span id="cb3-71"><a href="#cb3-71" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-72"><a href="#cb3-72" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> Y</span>
<span id="cb3-73"><a href="#cb3-73" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-74"><a href="#cb3-74" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_centroids(<span class="va">self</span>):</span>
<span id="cb3-75"><a href="#cb3-75" aria-hidden="true" tabindex="-1"></a>        centroids <span class="op">=</span> <span class="va">self</span>.centroids.cpu().detach().numpy()</span>
<span id="cb3-76"><a href="#cb3-76" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-77"><a href="#cb3-77" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> centroids</span>
<span id="cb3-78"><a href="#cb3-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-79"><a href="#cb3-79" aria-hidden="true" tabindex="-1"></a>centers <span class="op">=</span> [[<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">1</span>, <span class="dv">1</span>], [<span class="op">-</span><span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>], [<span class="dv">1</span>, <span class="op">-</span><span class="dv">1</span>]]</span>
<span id="cb3-80"><a href="#cb3-80" aria-hidden="true" tabindex="-1"></a>n_clusters <span class="op">=</span> <span class="bu">len</span>(centers)</span>
<span id="cb3-81"><a href="#cb3-81" aria-hidden="true" tabindex="-1"></a>n_samples <span class="op">=</span> <span class="dv">6000</span></span>
<span id="cb3-82"><a href="#cb3-82" aria-hidden="true" tabindex="-1"></a>X, Y <span class="op">=</span> make_blobs(n_samples<span class="op">=</span>n_samples, centers<span class="op">=</span>centers, cluster_std<span class="op">=</span><span class="fl">0.7</span>, random_state<span class="op">=</span><span class="dv">40</span>)</span>
<span id="cb3-83"><a href="#cb3-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-84"><a href="#cb3-84" aria-hidden="true" tabindex="-1"></a>gradient_kmeans <span class="op">=</span> GradientKMeans(<span class="dv">2</span>, <span class="dv">10</span>, <span class="dv">64</span>)</span>
<span id="cb3-85"><a href="#cb3-85" aria-hidden="true" tabindex="-1"></a>gradient_kmeans.fit(X)</span>
<span id="cb3-86"><a href="#cb3-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-87"><a href="#cb3-87" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> gradient_kmeans.predict(X)</span>
<span id="cb3-88"><a href="#cb3-88" aria-hidden="true" tabindex="-1"></a>centroids <span class="op">=</span> gradient_kmeans.get_centroids()</span>
<span id="cb3-89"><a href="#cb3-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-90"><a href="#cb3-90" aria-hidden="true" tabindex="-1"></a>plt.figure(<span class="dv">1</span>)</span>
<span id="cb3-91"><a href="#cb3-91" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> k, col <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="st">"r"</span>, <span class="st">"b"</span>, <span class="st">"g"</span>, <span class="st">"m"</span>, <span class="st">"y"</span>, <span class="st">"c"</span>]):</span>
<span id="cb3-92"><a href="#cb3-92" aria-hidden="true" tabindex="-1"></a>    cluster_data <span class="op">=</span> y_true <span class="op">==</span> k</span>
<span id="cb3-93"><a href="#cb3-93" aria-hidden="true" tabindex="-1"></a>    plt.scatter(X[cluster_data, <span class="dv">0</span>], X[cluster_data, <span class="dv">1</span>], c<span class="op">=</span>col, marker<span class="op">=</span><span class="st">"."</span>, s<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb3-94"><a href="#cb3-94" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-95"><a href="#cb3-95" aria-hidden="true" tabindex="-1"></a>plt.scatter(centroids[:, <span class="dv">0</span>], centroids[:, <span class="dv">1</span>], c<span class="op">=</span><span class="st">"w"</span>, s<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb3-96"><a href="#cb3-96" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<pre><code>94it [00:00, 591.45it/s, KMeans=1.01]                                                                                                                                                                                                                                                   
94it [00:00, 1217.76it/s, KMeans=0.943]                                                                                                                                                                                                                                                 
94it [00:00, 1212.54it/s, KMeans=0.921]                                                                                                                                                                                                                                                 
94it [00:00, 1192.24it/s, KMeans=0.941]                                                                                                                                                                                                                                                 
94it [00:00, 1196.55it/s, KMeans=0.928]                                                                                                                                                                                                                                                 
94it [00:00, 1179.02it/s, KMeans=0.89]                                                                                                                                                                                                                                                  
94it [00:00, 1181.19it/s, KMeans=0.922]                                                                                                                                                                                                                                                 
94it [00:00, 1178.50it/s, KMeans=0.932]                                                                                                                                                                                                                                                 
94it [00:00, 1096.57it/s, KMeans=0.932]                                                                                                                                                                                                                                                 
94it [00:00, 1188.89it/s, KMeans=0.909]                                                                                                                                                                                                                                                 </code></pre>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="K-means_files/K-means_14_1.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">png</figcaption>
</figure>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation column-page-right">
  <div class="nav-page nav-page-previous">
      <a href="../Machine Learning/7_Decision_Tree.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">40</span>&nbsp; <span class="chapter-title">Decision Tree</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js" type="text/javascript"></script>
<script type="text/javascript">
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    let pseudocodeOptions = {
      indentSize: el.dataset.indentSize || "1.2em",
      commentDelimiter: el.dataset.commentDelimiter || "//",
      lineNumber: el.dataset.lineNumber === "true" ? true : false,
      lineNumberPunc: el.dataset.lineNumberPunc || ":",
      noEnd: el.dataset.noEnd === "true" ? true : false,
      titlePrefix: el.dataset.algTitle || "Algorithm"
    };
    pseudocode.renderElement(el.querySelector(".pseudocode"), pseudocodeOptions);
  });
})(document);
(function(d) {
  d.querySelectorAll(".pseudocode-container").forEach(function(el) {
    titleSpan = el.querySelector(".ps-root > .ps-algorithm > .ps-line > .ps-keyword")
    titlePrefix = el.dataset.algTitle;
    titleIndex = el.dataset.chapterLevel ? el.dataset.chapterLevel + "." + el.dataset.pseudocodeIndex : el.dataset.pseudocodeIndex;
    titleSpan.innerHTML = titlePrefix + " " + titleIndex + " ";
  });
})(document);
</script>



</body></html>