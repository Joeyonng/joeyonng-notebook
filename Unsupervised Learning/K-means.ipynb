{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "089baa31",
   "metadata": {},
   "source": [
    "*Updated 01-12-2023 (First commited 02-27-2022)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bac2f4-5c40-4be1-b77d-fdbb2cb4681d",
   "metadata": {},
   "source": [
    "# K-means\n",
    "---\n",
    "\n",
    "1. K-means is used to cluster unlabeled instances in dataset into K groups that are defined by their centroids. The points in the same group can be further labeled or analyzed.\n",
    "2. We first randomly choose K centroids in the space. Then we cluster each data point to its nearest centroids and distance is calculated using sum of the square of the difference. After all data points have been assigned to a cluster, we recompute the centroids of the cluster by taking the average of all the data points that belong to that cluster. Then we cluster the data points again based on the new centroids and we repeat process until centroids don't really change.\n",
    "3. K-means is proved to find local minimum instead of global minimum. Thus the initialization of the centroids do matter to the outcome."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a686d9-a958-4e3c-80a9-318d1a0ecb3c",
   "metadata": {},
   "source": [
    "## Preliminary\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e137f1-022b-43c5-8752-dca8ac222c05",
   "metadata": {},
   "source": [
    "### Statistics\n",
    "\n",
    "#### Estimator\n",
    "\n",
    "In statistics, an estimator is a **function that takes as inputs a set of observations** sampled from an unknown probability distribution $P_{\\theta}(X)$ with the true parameter $\\theta$ and **outputs the best guess of the parameter** $\\hat{\\theta}$ of $P_{\\theta}(X)$. \n",
    "\n",
    "- An estimator is also a random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0e26e7-9f4b-4f77-ba5e-11336f079288",
   "metadata": {},
   "source": [
    "#### Bias\n",
    "\n",
    "The bias of an estimator measures **whether the expectation of the estimator is the same as the true parameter**. Let $\\hat{\\theta}$ be the output of an estimator for $\\theta$. The bias of $\\hat{\\theta}$ as an estimator for $\\theta$ is\n",
    "\n",
    "$$ \\operatorname{Bias}(\\hat{\\theta}, \\theta) = \\mathbb{E}[\\hat{\\theta}] - \\theta $$\n",
    "\n",
    "- $\\operatorname{Bias}(\\hat{\\theta}, \\theta) = 0$, then we say $\\hat{\\theta}$ is an **unbiased** estimator of $\\theta$.\n",
    "- $\\operatorname{Bias}(\\hat{\\theta}, \\theta) > 0$, $\\hat{\\theta}$ typically **overestimates** $\\theta$.\n",
    "- $\\operatorname{Bias}(\\hat{\\theta}, \\theta) < 0$, $\\hat{\\theta}$ typically **underestimates** $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c487c-ae2e-4d31-8116-1b108c9d3f44",
   "metadata": {},
   "source": [
    "#### Variance (of an estimator)\n",
    "\n",
    "The variance of an estimator measures the degree to which the **estimated parameters vary depending on the sampled observations**. Let $\\hat{\\theta}$ be the output of an estimator for $\\theta$. The variance of $\\hat{\\theta}$ as an estimator is\n",
    "\n",
    "$$ \\operatorname{Var}(\\hat{\\theta}) = \\mathbb{E}[(\\hat{\\theta} - \\mathbb{E}[\\hat{\\theta}])^{2}] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33bbcf3-b56e-474d-b89d-b688ed35c202",
   "metadata": {},
   "source": [
    "#### Mean squared error \n",
    "\n",
    "In statistics, the mean squared error (MSE) is a risk (loss) function measures the **difference between an estimator $\\hat{\\theta}$ with the true parameter $\\theta$**.\n",
    "\n",
    "$$ \\operatorname{MSE}(\\hat{\\theta}, \\theta) = \\mathbb{E}[(\\hat{\\theta} - \\theta)^{2}] $$\n",
    "\n",
    "If the estimator $\\hat{\\boldsymbol{\\theta}}$ and the true parameter $\\boldsymbol{\\theta}$ are vectors,\n",
    "\n",
    "$$ \\operatorname{MSE}(\\hat{\\boldsymbol{\\theta}}, \\boldsymbol{\\theta}) = \\mathbb{E}[\\lVert \\hat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta} \\rVert^{2}] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3add7a-e020-46d2-9b91-fdc238f9c9f7",
   "metadata": {},
   "source": [
    "#### Bias-variance decomposition\n",
    "\n",
    "A risk (loss) function can be often decomposed into a **bias, a variance and a noise term**. Here we take MSE as an example and expand it into a bias and variance term (noise is omitted).\n",
    "\n",
    "$$ \\operatorname{MSE}(\\hat{\\boldsymbol{\\theta}}, \\boldsymbol{\\theta}) = \\operatorname{Var}(\\hat{\\boldsymbol{\\theta}}) + \\operatorname{Bias}(\\hat{\\boldsymbol{\\theta}}, \\boldsymbol{\\theta})^{2} $$\n",
    "\n",
    ":::{admonition} Proof\n",
    ":class: dropdown\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\operatorname{MSE}(\\hat{\\boldsymbol{\\theta}}, \\boldsymbol{\\theta}) & = \\mathbb{E}[ \\lVert \\hat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta} \\rVert^{2} ] \\\\\n",
    "& = \\mathbb{E}[ \\lVert \\hat{\\boldsymbol{\\theta}} - \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] + \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] - \\boldsymbol{\\theta} \\rVert^{2}] & [\\text{add and subtract } \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] ] \\\\\n",
    "& = \\mathbb{E}[ \\lVert \\hat{\\boldsymbol{\\theta}} - \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] \\rVert^{2} + 2 \\lVert \\hat{\\boldsymbol{\\theta}} - \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] \\rVert \\lVert \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] - \\boldsymbol{\\theta} \\rVert + \\lVert \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] - \\boldsymbol{\\theta} \\rVert^{2} ] & [(a + b)^{2} = a^{2} + 2ab + b^{2}] \\\\\n",
    "& = \\mathbb{E}[ \\lVert \\hat{\\boldsymbol{\\theta}} - \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] \\rVert^{2} ] + \\mathbb{E}[ 2 \\lVert \\hat{\\boldsymbol{\\theta}} - \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] \\rVert \\lVert \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] - \\boldsymbol{\\theta} \\rVert ] + \\mathbb{E}[ \\lVert \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] - \\boldsymbol{\\theta} \\rVert^{2} ] & [\\text{Linearity of Expectation}] \\\\\n",
    "& = \\operatorname{Var}(\\hat{\\boldsymbol{\\theta}}) + 2\\mathbb{E}[ \\lVert \\hat{\\boldsymbol{\\theta}} - \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] \\rVert] \\mathbb{E}[ \\lVert \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] - \\boldsymbol{\\theta} \\rVert ] + \\mathbb{E}[ \\operatorname{Bias}(\\hat{\\boldsymbol{\\theta}}, \\boldsymbol{\\theta})^{2} ] \\\\\n",
    "& = \\operatorname{Var}(\\hat{\\boldsymbol{\\theta}}) + \\operatorname{Bias}(\\hat{\\boldsymbol{\\theta}}, \\boldsymbol{\\theta})^{2} & [\\mathbb{E}[ \\lVert \\hat{\\boldsymbol{\\theta}} - \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] \\rVert] = \\lVert \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] - \\mathbb{E}[\\hat{\\boldsymbol{\\theta}}] \\rVert = 0] \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaf3f70-0a24-426a-a28f-383decb59617",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem formulation\n",
    "---\n",
    "\n",
    "- K-means clustering algorithm is a unsupervised learning algorithm that aims to **cluster similar instances into the same group**. \n",
    "\n",
    "- The input to the algorithm is $n$ instances $\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\dots, \\mathbf{x}_{n} \\in \\mathbb{R}^{d}$ **without labels** and the output of the algorithm is $k$ centroids $\\mathbf{u}_{1}, \\mathbf{u}_{2}, \\dots, \\mathbf{u}_{k} \\in \\mathbb{R}^{d}$, where $k$ is a hyperparameter used to control the number of centroids desired. \n",
    "        \n",
    "- The goal of K-means clustering is to find the best $k$ centroids that minimizes a loss function (often **MSE loss** of the **$L_{2}$ norm or euclidean distance** of the difference vector) that captures the overall distances between the instances and the centroids assigned.\n",
    "\n",
    "    $$ \\operatorname{loss}(\\mathbf{u}_{1}, \\dots, \\mathbf{u}_{k}) = \\sum_{i = 1}^{n} \\lVert \\mathbf{x}_{i} - \\mathbf{u}_{x_{i}} \\rVert^{2} $$\n",
    "\n",
    "    where $\\mathbf{u}_{x_{i}}$ is the centroid that instance $\\mathbf{x}_{i}$ is assigned to.\n",
    "   \n",
    "- Another way to write the loss function is to consider the distances between each centroid and the instances in the cluster that the centroid represents. The benefit of this formulation is that the clusters that the centroids represent are separated as variables, which is easier to do algorithm analyzing.\n",
    "\n",
    "    $$ \\operatorname{loss}(\\mathbf{u}_{1}, \\dots, \\mathbf{u}_{k}, C_{\\mathbf{u}_{1}}, \\dots, C_{\\mathbf{u}_{k}}) = \\sum_{i = 1}^{k} \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}_{i}}} \\lVert \\mathbf{x} - \\mathbf{u}_{i} \\rVert^{2} $$\n",
    "    \n",
    "    where $C_{\\mathbf{u}_{i}}$ is the cluster that centroid $\\mathbf{u}_{i}$ represents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5813393e-68d6-48bf-8d84-defe5720107d",
   "metadata": {},
   "source": [
    "## K-means using Lloyd's algorithm\n",
    "---\n",
    "\n",
    "### Algorithm \n",
    "\n",
    "> **Function**: K-means  \n",
    "> **Input**: a set of instances $\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\dots, \\mathbf{x}_{n}$ and a hyperparameter $k$.  \n",
    "> **Output**: a set of centroids $\\mathbf{u}_{1}, \\mathbf{u}_{2}, \\dots, \\mathbf{u}_{k}$.\n",
    "> 1. Initialize cluster centroids $\\mathbf{u}_{1}, \\mathbf{u}_{2}, \\dots, \\mathbf{u}_{k}$ by randomly drawing $k$ instances as the centroids.\n",
    "> 2. Repeat until convergence or a fixed number of iterations: \n",
    ">     1. **Assignment step**: get the nearest centroid $\\mathbf{c}_{i}$ for each instance $\\mathbf{x}_{i}$:\n",
    ">\n",
    ">         $$ \\mathbf{c}_{i} = \\arg \\min_{j} \\lVert \\mathbf{x}_{i} - \\mathbf{u}_{j} \\rVert^{2} $$\n",
    ">\n",
    ">     2. **Refitting step**: update each centroid based on the instances in its cluster:\n",
    ">\n",
    ">         $$ \\mathbf{u}_{j} = \\frac{\\sum_{i}^{m} \\mathbb{1}_{\\mathbf{c}_i = j} \\mathbf{x}_{i}}{\\sum_{i}^{m} \\mathbb{1}_{\\mathbf{c}_{i} = j}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7487f9-7d17-49a3-b041-d252fcb52d46",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Convergence of Lloyd's algorithm\n",
    "\n",
    "K-means solved using Lloyd's algorithm is guaranteed to converge to a local minimum because:\n",
    "- The loss value is guaranteed to be smaller or stay the same in the assignment step because each instance $\\mathbf{x}_{i}$ gets the nearest centroid. \n",
    "\n",
    "    $$ \\operatorname{loss}( \\mathbf{u}_{1}, \\dots, \\mathbf{u}_{k}, (C_{\\mathbf{u}_{1}}, \\dots, C_{\\mathbf{u}_{k}})^{t + 1} ) \\leq \\operatorname{loss}( \\mathbf{u}_{1}, \\dots, \\mathbf{u}_{k}, (C_{\\mathbf{u}_{1}}, \\dots, C_{\\mathbf{u}_{k}})^{t} ) $$\n",
    "        \n",
    "- The loss value is guaranteed to be smaller or stay the same in the refitting step.\n",
    "\n",
    "    $$ \\operatorname{loss}( (\\mathbf{u}_{1}, \\dots, \\mathbf{u}_{k})^{t + 1}, (C_{\\mathbf{u}_{1}}, \\dots, C_{\\mathbf{u}_{k}})^{t + 1} ) \\leq \\operatorname{loss}( (\\mathbf{u}_{1}, \\dots, \\mathbf{u}_{k})^{t}, (C_{\\mathbf{u}_{1}}, \\dots, C_{\\mathbf{u}_{k}})^{t + 1} ) $$\n",
    "    \n",
    "    To see why this is true, consider a single centroid-cluster pair $\\mathbf{u}$ and $C_{\\mathbf{u}}$, for all instances $\\mathbf{x}_{1}, \\mathbf{x}_{2}, \\dots, \\mathbf{x}_{n}$ that belongs to the cluster $C_{\\mathbf{u}}$, the loss function $\\operatorname{loss}(\\mathbf{u}, C_{\\mathbf{u}})$ will be minimized when $\\mathbf{u}$ is the average of the instances in $C_{\\mathbf{u}}$:\n",
    "    \n",
    "    $$ \\boldsymbol{\\mu} = \\frac{1}{n} \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} \\mathbf{x}_{i} = \\arg \\min_{\\mathbf{u} \\in \\mathbb{R}^{d}} \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} \\lVert \\mathbf{x} - \\mathbf{u} \\rVert^{2} = \\arg \\min_{\\mathbf{u} \\in \\mathbb{R}^{d}} \\operatorname{loss}(\\mathbf{u}, C_{\\mathbf{u}}) $$\n",
    "    \n",
    "    because of the equation below derived from the bias-variance decomposition of MSE function:\n",
    "    \n",
    "    $$ \\operatorname{loss}(\\mathbf{u}, C_{\\mathbf{u}}) = \\operatorname{loss}(\\mathbf{\\boldsymbol{\\mu}}, C_{\\mathbf{\\mathbf{u}}}) + n \\lVert \\boldsymbol{\\mu} - \\mathbf{u} \\rVert $$\n",
    "    \n",
    "    where $n$ is the number of instances in the cluster $C_{\\mathbf{u}}$.\n",
    "    \n",
    "    :::{admonition} Proof\n",
    "    :class: dropdown\n",
    "    \n",
    "    $$\n",
    "    \\begin{align}\n",
    "    \\operatorname{loss}(\\mathbf{u}, C_{\\mathbf{u}}) & = \\operatorname{loss}(\\boldsymbol{\\mu}, C_{\\mathbf{u}}) + n\\lVert \\boldsymbol{\\mu} - \\mathbf{u} \\rVert^{2} \\\\\n",
    "    & = \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} \\lVert \\mathbf{x} - \\boldsymbol{\\mu} \\rVert^{2} + n\\lVert \\boldsymbol{\\mu} - \\mathbf{u} \\rVert^{2} \\\\\n",
    "    & = \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} \\left( \\lVert \\mathbf{x} \\rVert^{2} - 2\\lVert \\mathbf{x} \\rVert \\lVert \\boldsymbol{\\mu} \\rVert + \\lVert \\boldsymbol{\\mu} \\rVert^{2} \\right) + n\\left( \\lVert \\boldsymbol{\\mu} \\rVert^{2} - 2 \\lVert \\boldsymbol{\\mu} \\rVert \\lVert \\mathbf{u} \\rVert + \\lVert \\mathbf{u} \\rVert^{2} \\right) \\\\\n",
    "    & = \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} \\left( \\lVert \\mathbf{x} \\rVert^{2} - 2\\lVert \\mathbf{x} \\rVert \\lVert \\frac{S}{n} \\rVert + \\lVert \\frac{S}{n} \\rVert^{2} \\right) + n\\left( \\lVert \\frac{S}{n} \\rVert^{2} - 2 \\lVert \\boldsymbol{\\mu} \\rVert \\lVert \\mathbf{u} \\rVert + \\lVert \\mathbf{u} \\rVert^{2} \\right) & \\left[ \\text{replace some } \\boldsymbol{\\mu} \\text{ with } \\frac{S}{n} \\text{ where } S = \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} \\mathbf{x} \\right] \\\\\n",
    "    & = \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} \\lVert \\mathbf{x} \\rVert^{2} - \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} 2\\lVert \\mathbf{x} \\rVert \\lVert \\frac{S}{n} \\rVert + \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} \\lVert \\frac{S}{n} \\rVert^{2} + n\\lVert \\frac{S}{n} \\rVert^{2} - 2n\\lVert \\boldsymbol{\\mu} \\rVert \\lVert \\mathbf{u} \\rVert + n\\lVert \\mathbf{u} \\rVert^{2} \\\\\n",
    "    & = \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} \\lVert \\mathbf{x} \\rVert^{2} - 2 \\lVert S \\rVert \\lVert \\frac{S}{n} \\rVert + n\\lVert \\frac{S}{n} \\rVert^{2} + n\\lVert \\frac{S}{n} \\rVert^{2} - 2n\\lVert \\boldsymbol{\\mu} \\rVert \\lVert \\mathbf{u} \\rVert + n\\lVert \\mathbf{u} \\rVert^{2} & \\left[ \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} \\lVert x \\rVert = \\lVert S \\rVert \\text{ and } \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} 1 = n \\right] \\\\ \n",
    "    & = \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} \\lVert \\mathbf{x} \\rVert^{2} - 2n\\lVert \\boldsymbol{\\mu} \\rVert \\lVert \\mathbf{u} \\rVert + n\\lVert \\mathbf{u} \\rVert^{2} & \\left[ \\lVert S \\rVert \\lVert \\frac{S}{n} \\rVert = n\\lVert \\frac{S}{n} \\rVert^{2}  \\right] \\\\ \n",
    "    & = \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} ( \\lVert \\mathbf{x} \\rVert^{2} - 2\\lVert \\boldsymbol{\\mu} \\rVert \\lVert \\mathbf{u} \\rVert + \\lVert \\mathbf{u} \\rVert^{2} ) \\\\\n",
    "    & = \\sum_{\\mathbf{x} \\in C_{\\mathbf{u}}} \\lVert \\mathbf{x} - \\mathbf{u} \\rVert^{2} \\\\\n",
    "    \\end{align}\n",
    "    $$\n",
    "    \n",
    "    Since $\\lvert C_{\\mathbf{\\mathbf{u}}} \\rvert \\cdot \\lVert \\boldsymbol{\\mu} - \\mathbf{u} \\rVert$ is always positive, \n",
    "    \n",
    "    $$ \\operatorname{loss}(\\boldsymbol{\\mu}, C_{\\mathbf{u}}) \\leq \\operatorname{loss}(\\mathbf{\\mathbf{u}}, C_{\\mathbf{\\mathbf{u}}}) $$\n",
    "    \n",
    "    :::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0aa3f6-8503-40e3-ac66-277041f17143",
   "metadata": {},
   "source": [
    "## The K-means++ initializer\n",
    "---\n",
    "\n",
    "Although the default behavior of the K-means algorithm is to initialize the centroids randomly, the quality of the final solution depends heavily on the initialization because K-means is only guaranteed to converge to a local point. \n",
    "\n",
    "The K-means++ initializer is a special way of initializing the centroids so that\n",
    "- the convergence of K-means is faster,\n",
    "- the final loss is bounded (the quality of the final solution won't be very bad).\n",
    "\n",
    "> 1. Pick an instance $\\mathbf{x}$ uniformly at random and set $T \\gets \\{\\mathbf{x}\\}$\n",
    "> 1. While $\\lvert T \\rvert < k$:\n",
    ">     1. Pick an instance $\\mathbf{x}$ at random, with probability proportional to \n",
    ">     \n",
    ">         $$ \\operatorname{cost}(\\mathbf{x}, T) = \\min_{\\mathbf{u} \\in T} \\lVert \\mathbf{x} - \\mathbf{u} \\rVert^{2} $$\n",
    ">     \n",
    ">     1. Add $\\mathbf{x}$ to $T$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94462151-be35-40c2-8870-f3d115594c47",
   "metadata": {},
   "source": [
    "## Reference \n",
    "---\n",
    "\n",
    "1. https://stanford.edu/~cpiech/cs221/handouts/kmeans.html\n",
    "1. https://cseweb.ucsd.edu/~dasgupta/291-geom/kmeans.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23394e3-09e8-4819-a5fc-ff274da2f426",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Implementation\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7e33c5-6ece-4a86-908b-3cfa8e5eddef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "94it [00:00, 591.45it/s, KMeans=1.01]                                                                                                                                                                                                                                                   \n",
      "94it [00:00, 1217.76it/s, KMeans=0.943]                                                                                                                                                                                                                                                 \n",
      "94it [00:00, 1212.54it/s, KMeans=0.921]                                                                                                                                                                                                                                                 \n",
      "94it [00:00, 1192.24it/s, KMeans=0.941]                                                                                                                                                                                                                                                 \n",
      "94it [00:00, 1196.55it/s, KMeans=0.928]                                                                                                                                                                                                                                                 \n",
      "94it [00:00, 1179.02it/s, KMeans=0.89]                                                                                                                                                                                                                                                  \n",
      "94it [00:00, 1181.19it/s, KMeans=0.922]                                                                                                                                                                                                                                                 \n",
      "94it [00:00, 1178.50it/s, KMeans=0.932]                                                                                                                                                                                                                                                 \n",
      "94it [00:00, 1096.57it/s, KMeans=0.932]                                                                                                                                                                                                                                                 \n",
      "94it [00:00, 1188.89it/s, KMeans=0.909]                                                                                                                                                                                                                                                 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://takoscribe.com/2020/12/29/kmeans-clustering-with-pytorch/\n",
    "\n",
    "import functools\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "class GradientKMeans(nn.Module):\n",
    "    def __init__(self, num_centroids, n_epochs, batch_size, lr=1e-2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_centroids = num_centroids\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.lr = lr\n",
    "\n",
    "    def _initialize(self, x):\n",
    "        assignment = [i % self.num_centroids for i in range(x.size(0))]\n",
    "        random_indices = torch.randperm(len(assignment))\n",
    "        random_assignment = torch.LongTensor(assignment)[random_indices]\n",
    "        for i in range(self.num_centroids):\n",
    "            self.centroids.data[i] = x[random_assignment == i].mean(0)\n",
    "        \n",
    "    def _assign(self, x):\n",
    "        indices = ((x[:,None] - self.centroids) ** 2).mean(2).argmin(1)\n",
    "        \n",
    "        return indices\n",
    " \n",
    "    def forward(self, x):\n",
    "        return self._assign(x)\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.centroids = nn.Parameter(torch.zeros(self.num_centroids, X.shape[1]))\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        self.loss = nn.MSELoss()\n",
    "        centroids_init = False\n",
    "        \n",
    "        cost_window = 25\n",
    "        costs = []\n",
    "\n",
    "        X_t = torch.utils.data.TensorDataset(torch.Tensor(X), torch.zeros((X.shape[0], )))\n",
    "        iterator = torch.utils.data.DataLoader(X_t, batch_size=self.batch_size, shuffle=True)\n",
    "        for i in range(self.n_epochs):\n",
    "            with tqdm.tqdm(total=len(X) // self.batch_size) as progress_bar:\n",
    "                for x, _ in iterator:\n",
    "                    if not centroids_init: \n",
    "                        self._initialize(x)\n",
    "                        centroids_init = True\n",
    "\n",
    "                    assignment = self._assign(x)\n",
    "                    \n",
    "                    self.optimizer.zero_grad()\n",
    "                    means = self.centroids[assignment]\n",
    "                    cur_cost = self.loss(x, means)\n",
    "                    cur_cost.backward()\n",
    "                    self.optimizer.step()\n",
    "                    \n",
    "                    costs.append(cur_cost.item())\n",
    "                    \n",
    "                    progress_bar.set_postfix({\n",
    "                        'KMeans': float(functools.reduce(lambda x, y: x + y, costs[-cost_window:])) /  len(costs[-cost_window:])\n",
    "                    })\n",
    "                    progress_bar.update(1) # 1 step\n",
    "                    \n",
    "    def predict(self, X):\n",
    "        Y = self(torch.Tensor(X))\n",
    "        \n",
    "        return Y\n",
    "    \n",
    "    def get_centroids(self):\n",
    "        centroids = self.centroids.cpu().detach().numpy()\n",
    "        \n",
    "        return centroids\n",
    "\n",
    "centers = [[-1, 1], [1, 1], [-1, -1], [1, -1]]\n",
    "n_clusters = len(centers)\n",
    "n_samples = 6000\n",
    "X, Y = make_blobs(n_samples=n_samples, centers=centers, cluster_std=0.7, random_state=40)\n",
    "\n",
    "gradient_kmeans = GradientKMeans(2, 10, 64)\n",
    "gradient_kmeans.fit(X)\n",
    "\n",
    "y_true = gradient_kmeans.predict(X)\n",
    "centroids = gradient_kmeans.get_centroids()\n",
    "\n",
    "plt.figure(1)\n",
    "for k, col in enumerate([\"r\", \"b\", \"g\", \"m\", \"y\", \"c\"]):\n",
    "    cluster_data = y_true == k\n",
    "    plt.scatter(X[cluster_data, 0], X[cluster_data, 1], c=col, marker=\".\", s=10)\n",
    "\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1], c=\"w\", s=50)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
