{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67e44f3-f60b-44bc-b49a-8a651d48c9f1",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "Need to mention that the following notes are always assuming the function is continuous at all points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708caf22-6aa9-418d-8d8d-111c529ff93c",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "## Scalar-valued and vector-valued functions \n",
    "\n",
    "A scalar-valued function $f$ outputs a scalar, \n",
    "while a vector-valued function $\\mathbf{f}$ outputs a vector.\n",
    "\n",
    "A vector-valued function can be interpreted as a vector of scalar-valued functions\n",
    "\n",
    "$$\n",
    "\\mathbf{f} = \n",
    "\\begin{bmatrix}\n",
    "f_{1} \\\\\n",
    "\\vdots \\\\\n",
    "f_{m} \\\\\n",
    "\\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "## Univariate and multivariate functions \n",
    "\n",
    "A univariate function takes a scalar $x$ as the input, \n",
    "while a multivariate function takes a vector $\\mathbf{x}$ as the input "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1c9498-a7e9-442e-8105-c27f0e835e2f",
   "metadata": {},
   "source": [
    "# Derivatives for scalar-valued functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92b897a-7d47-48fb-90ea-d28a62d738fa",
   "metadata": {},
   "source": [
    "## Ordinary (univariate) Derivatives\n",
    "\n",
    "The **derivative function** of a univariate scalar-valued function $f$, denoted $\\frac{d f}{d x}$ or $f'$, is another univariate scalar-valued function that takes $x$ as the input and outputs the **derivative** of the function at point $x$:\n",
    "\n",
    "$$\n",
    "f' (x) = \\frac{d f}{d x} (x) = \\lim_{h \\rightarrow 0} \\frac{f (x + h) - f (x)}{h}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc07180b-a3c5-4e12-97a3-a7404550923a",
   "metadata": {},
   "source": [
    "The derivative of $f$ at point $x$ is the slope of the tangent line to the function $f$ at the point $x$, which also represents the rate of the change of $f$ at $x$ in the positive (increasing) direction. \n",
    "\n",
    ":::{prf:proof} Derivative as the rate of change\n",
    ":class: dropdown\n",
    "\n",
    "A line has the form of \n",
    "\n",
    "$$\n",
    "y = k x + b\n",
    "$$\n",
    "\n",
    "where $k$ is the slope of the line and $b$ represents the interception of the line on the $y$ axis. \n",
    "\n",
    "We can calculate the slope of the line if we know the two points $(x_{1}, y_{1})$ and $(x_{2}, y_{2})$ that are on the line\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{2} - y_{1} \n",
    "& = k x_{2} + b - k x_{1} + b\n",
    "\\\\\n",
    "& = k (x_{2} - x_{1}) \n",
    "\\\\\n",
    "k\n",
    "& = \\frac{y_{2} - y_{1}}{x_{2} - x_{1}}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus, if we set $x' = x + h$,\n",
    "the equation\n",
    "\n",
    "$$\n",
    "\\frac{f (x + h) - f (x)}{h} = \\frac{f (x') - f(x)}{x' - x} \n",
    "$$\n",
    "\n",
    "represents the the slope of the line connecting the points $(x', f (x'))$ and $(x, f(x))$.\n",
    "\n",
    "As $h$ getting smaller,\n",
    "the line connecting the points $(x', f (x'))$ and $(x, f(x))$ is becoming the tangent line of $f(x)$ at point $x$.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d800652-baa3-47b2-a339-680dbadcac80",
   "metadata": {},
   "source": [
    "## Multivariate Derivatives "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c508190a-d9fd-46dc-9a36-2fd251b735de",
   "metadata": {},
   "source": [
    "### Directional derivatives\n",
    "\n",
    "Given a non-zero vector $\\mathbf{u} \\in \\mathbb{R}^{n}$, the **directional derivative function** of a scalar-valued multivariate function $f$, denoted $D_{\\mathbf{u}} f$, is another scalar-valued multivariate function that takes $\\mathbf{x} \\in \\mathbb{R}^{n}$ as the input and outputs the **directional derivative** of the function with respect to $\\mathbf{u}$ at point $\\mathbf{x}$: \n",
    "\n",
    "$$\n",
    "D_{\\mathbf{u}} f (\\mathbf{x}) = \\lim_{h \\rightarrow 0} \\frac{f (\\mathbf{x} + h \\mathbf{u}) - f (\\mathbf{x})}{h \\lVert \\mathbf{u} \\rVert}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02a7e76-88e7-4f99-92cb-1037c6b4cbba",
   "metadata": {},
   "source": [
    "If the given vector $\\mathbf{u}$ is a unit vector ($\\lVert \\mathbf{u} \\rVert = 1$), the directional derivative function is simplified to \n",
    "\n",
    "$$\n",
    "D_{\\mathbf{u}} f (\\mathbf{x}) = \\lim_{h \\rightarrow 0} \\frac{f (\\mathbf{x} + h \\mathbf{u}) - f (\\mathbf{x})}{h}.\n",
    "$$\n",
    "\n",
    "The directional derivative of $f$ with respect to the vector $\\mathbf{u}$ at the point $\\mathbf{x}$ represents the rate of change of $f$ at $\\mathbf{x}$ in the positive direction of $\\mathbf{u}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f15a1a-8741-4278-8206-695c6d8c9f84",
   "metadata": {},
   "source": [
    "#### Reparameterization of directional derivatives\n",
    "\n",
    "Given the vectors $\\mathbf{x}$ and $\\mathbf{u}$, \n",
    "the univariate function \n",
    "\n",
    "$$\n",
    "g (\\epsilon) = f (\\mathbf{x} + \\epsilon \\mathbf{u})\n",
    "$$ \n",
    "\n",
    "describes the values of $f$ along a particular line that starts from the point $\\mathbf{x}$ and goes in the direction of the vector $\\mathbf{u}$.\n",
    "\n",
    "The derivative of function $g$ at point $\\epsilon = 0$ gives the rate of change of $g$ at point $0$ and also the rate of change of $f$ at $\\mathbf{x}$ in the direction of $\\mathbf{u}$, which is exactly the directional derivative:\n",
    "\n",
    "$$\n",
    "D_{u} f (\\mathbf{x}) \\lVert \\mathbf{u} \\rVert = \\frac{d}{d \\epsilon} g (\\epsilon) \\Big|_{\\epsilon = 0} = \\frac{d}{d \\epsilon} f (\\mathbf{x} + \\epsilon \\mathbf{u}) \\Big|_{\\epsilon = 0}.\n",
    "$$\n",
    "\n",
    "This observation provides an alternative way to compute a directional derivative that only requires computing an ordinary derivative. \n",
    "\n",
    ":::{prf:proof} Reparameterization of directional derivative\n",
    ":class: dropdown\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{d g}{d \\epsilon} (\\epsilon) \\Big|_{\\epsilon = 0}\n",
    "& = \\lim_{h \\rightarrow 0} \\frac{c (\\epsilon + h) - c (\\epsilon)}{h} \\Big|_{\\epsilon = 0}\n",
    "\\\\\n",
    "& = \\lim_{h \\rightarrow 0} \\frac{f (\\mathbf{x} + (\\epsilon + h) \\mathbf{u}) - f (\\mathbf{x} + \\epsilon \\mathbf{u})}{h} \\Big|_{\\epsilon = 0}\n",
    "\\\\\n",
    "& = \\lim_{h \\rightarrow 0} \\frac{f (\\mathbf{x} + h \\mathbf{u}) - f (\\mathbf{x})}{h}\n",
    "\\\\\n",
    "& = D_{\\mathbf{u}} f (\\mathbf{x}) \\lVert \\mathbf{u} \\rVert.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5c612-7fc8-4d7e-8b18-7e2b9d77b7d1",
   "metadata": {},
   "source": [
    "### Partial derivatives \n",
    "\n",
    "The **partial derivative function** of a multivariate function $f$ with respect to a dimension $i$, denoted as $\\frac{\\partial f}{\\partial x_{i}}$, is a special case of the directional derivative function, where the given vector $\\mathbf{u}$ must be a standard basis vector $\\mathbf{e}_{i}$ of the dimension $i$: \n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x_{i}} (\\mathbf{x}) = D_{\\mathbf{e}_{i}} f (\\mathbf{x}) = \\lim_{h \\rightarrow 0} \\frac{f (\\mathbf{x} + h \\mathbf{e}_{i}) - f (\\mathbf{x})}{h}.\n",
    "$$\n",
    "\n",
    "The partial derivative of $f$ with respect to $\\mathbf{e}_{i}$ at $\\mathbf{x}$ gives the rate of the change of the function at $\\mathbf{x}$ along the direction of the $i$th dimension of the vector space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99eca984-5c35-4d3e-b5e4-b7fc40ec08ac",
   "metadata": {},
   "source": [
    "The partial derivative $\\frac{\\partial f}{\\partial x_{i}} (\\mathbf{x})$ can be calculated using the orindary derivative\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial x_{i}} (\\mathbf{x}) = \\frac{d f^{\\mathbf{x}}}{d x_{i}} (x_{i})\n",
    "$$\n",
    "\n",
    "where $f^{\\mathbf{x}}$ is a univariate function obtained by setting all variables except $x_{i}$ in $f$ as constants\n",
    "\n",
    "$$\n",
    "f^{\\mathbf{x}} (x_{i}) = f (\\mathbf{x})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b604386a-7b57-4351-9d00-cbf5f3a74fa2",
   "metadata": {},
   "source": [
    "### Gradients\n",
    "\n",
    "The **gradient function** of a multivariate function $f$, denoted as $\\nabla f$, is a vector-valued function, \n",
    "where each element in the output vector is the partial derivative of $f$ with respect to all standard basis vectors\n",
    "\n",
    "$$\n",
    "\\nabla f (\\mathbf{x}) = \n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial x_{1}} (\\mathbf{x}) \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial x_{n}} (\\mathbf{x})\n",
    "\\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ee4574-d498-47d2-81c3-5b6198d5ab59",
   "metadata": {},
   "source": [
    "The directional derivative with respect to any non-zero vector $\\mathbf{u}$ of function $f$ at point $x$ can be readily calculated using its gradient as follows:\n",
    "\n",
    "$$\n",
    "D_{\\mathbf{u}} f (\\mathbf{x}) = \\nabla f (\\mathbf{x}) \\cdot \\frac{\\mathbf{u}}{\\lVert \\mathbf{u} \\rVert}.\n",
    "$$\n",
    "\n",
    ":::{prf:proof} Directional derivative calculated using gradient\n",
    ":class: dropdown\n",
    "\n",
    "Using the Reparameterization of directional derivative,\n",
    "we can write the directional derivative as \n",
    "\n",
    "$$\n",
    "D_{\\mathbf{u}} f (\\mathbf{x}) \\lVert \\mathbf{u} \\rVert = \\frac{d f}{d \\epsilon} (\\mathbf{x} + \\epsilon \\mathbf{u}) \\Big|_{\\epsilon = 0}.\n",
    "$$\n",
    "\n",
    "By using the chain rule and writing $\\mathbf{g} (\\epsilon) = \\mathbf{x} + \\epsilon \\mathbf{u}$,\n",
    "we can also see that the derivative of the univariate function $f (\\mathbf{x} + \\epsilon \\mathbf{u})$ at point $\\epsilon = 0$ can be written as \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{d f}{d \\epsilon} (\\mathbf{x} + \\epsilon \\mathbf{u}) \\Big|_{\\epsilon = 0}\n",
    "& = \\sum_{i=1}^{m} \\frac{\\partial f}{\\partial g_{i} (\\epsilon)} (\\mathbf{g} (\\epsilon)) \\frac{d g_{i}}{d \\epsilon} (\\epsilon) \\Big|_{\\epsilon = 0}\n",
    "\\\\\n",
    "& = \\sum_{i=1}^{m} \\frac{\\partial f}{\\partial (x_{i} + \\epsilon u_{i})} (\\mathbf{x} + \\epsilon \\mathbf{u}) \\frac{d (x_{i} + \\epsilon u_{i})}{d \\epsilon} (\\epsilon) \\Big|_{\\epsilon = 0}\n",
    "\\\\\n",
    "& = \\sum_{i=1}^{m} \\frac{\\partial f}{\\partial (x_{i} + \\epsilon u_{i})} (\\mathbf{x} + \\epsilon \\mathbf{u}) u_{i} \\Big|_{\\epsilon = 0}\n",
    "\\\\\n",
    "& = \\sum_{i=1}^{m} \\frac{\\partial f}{\\partial x_{i}} (\\mathbf{x}) u_{i}\n",
    "\\\\\n",
    "& = \\nabla f (\\mathbf{x}) \\cdot \\mathbf{u}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus, \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D_{\\mathbf{u}} f (\\mathbf{x}) = \\nabla f (\\mathbf{x}) \\cdot \\frac{\\mathbf{u}}{\\lVert \\mathbf{u} \\rVert}.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f478ecce-4021-44f7-9f9b-b77a6a99cdb8",
   "metadata": {},
   "source": [
    "It turns out that the directional derivative of function $f$ at point $\\mathbf{x}$ with respect to the direction of the gradient vector is the largest. \n",
    "That is, the gradient of $f$ at point $\\mathbf{x}$ is the direction of steepest ascent along the function surface at the point $\\mathbf{x}$\n",
    "\n",
    "$$\n",
    "\\nabla f (\\mathbf{x}) = \\arg\\max_{\\mathbf{u}} D_{\\mathbf{u}} f(x).\n",
    "$$\n",
    "\n",
    ":::{prf:proof} Gradient as the steepest ascent direction\n",
    ":class: dropdown\n",
    "\n",
    "According to the definition of a dot product, \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D_{\\mathbf{u}} f (\\mathbf{x}) \n",
    "& = \\frac{\n",
    "\\nabla f (\\mathbf{x}) \\cdot \\mathbf{u}}{\\lVert \\mathbf{u} \\rVert}\n",
    "\\\\\n",
    "& = \\frac{\\lVert \\nabla f (\\mathbf{x}) \\rVert \\lVert \\mathbf{u} \\rVert \\cos (\\theta)}{\\lVert \\mathbf{u} \\rVert}\n",
    "\\\\\n",
    "& = \\lVert \\nabla f (\\mathbf{x}) \\rVert \\cos (\\theta)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where $\\theta$ is the angle between the vector $\\nabla f(x)$ and $\\mathbf{u}$. \n",
    "\n",
    "Since $\\lVert \\nabla f (\\mathbf{x}) \\rVert$ is fixed given $\\mathbf{x}$, \n",
    "\n",
    "$$\n",
    "\\max_{\\mathbf{u}} D_{\\mathbf{u}} f (\\mathbf{x}) = \\max_{\\theta} \\cos (\\theta),\n",
    "$$\n",
    "\n",
    "which is maximized when $\\mathbf{u}$ has the same direction as $\\nabla f (\\mathbf{x})$. \n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a829a3a6-fbfd-47d7-92a9-e2985f8b11a9",
   "metadata": {},
   "source": [
    "The directional derivative of the function $f$ with respect to the direction of the gradient vector $\\nabla f (\\mathbf{x})$ at point $\\mathbf{x}$ is the magnitude of the gradient vector\n",
    "\n",
    "$$\n",
    "D_{\\nabla f (\\mathbf{x})} f (\\mathbf{x}) = \\lVert \\nabla f (\\mathbf{x}) \\rVert.\n",
    "$$\n",
    "\n",
    ":::{prf:proof} The magnitude of the gradient vector gives the rate of the change along the steepest ascent direction\n",
    ":class: dropdown\n",
    "\n",
    "Replacing the $\\mathbf{u}$ with $\\nabla f (\\mathbf{x})$ in the equation\n",
    "\n",
    "$$\n",
    "D_{\\mathbf{u}} f (\\mathbf{x}) = \\nabla f (\\mathbf{x}) \\cdot \\frac{\\mathbf{u}}{\\lVert \\mathbf{u} \\rVert}\n",
    "$$\n",
    "\n",
    "to get\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D_{\\nabla f (\\mathbf{x})} f (\\mathbf{x}) \n",
    "& = \\nabla f (\\mathbf{x}) \\cdot \\frac{\\nabla f (\\mathbf{x})}{\\lVert \\nabla f (\\mathbf{x}) \\rVert}\n",
    "\\\\\n",
    "& = \\frac{\\lVert \\nabla f (\\mathbf{x}) \\rVert^{2}}{\\lVert \\nabla f (\\mathbf{x}) \\rVert}\n",
    "\\\\\n",
    "& = \\lVert \\nabla f (\\mathbf{x}) \\rVert.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c339a365-ed34-4089-bde8-45b0a8ba5799",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Derivatives for vector-valued functions \n",
    "\n",
    "Since the vector-valued functions are just the vector version of their corresponding scalar-valued functions,\n",
    "all types of derivatives for vector-valued functions are the vectorized versions of their corresponding derivatives for the scalar-valued functions.\n",
    "\n",
    "- Ordinary derivative functions\n",
    "\n",
    "    $$\n",
    "    \\mathbf{f}' (x) = \\frac{d \\mathbf{f}}{d x} (x) = \\begin{bmatrix}\n",
    "    f_{1}' (x) \\\\\n",
    "    \\vdots \\\\\n",
    "    f_{m}' (x) \\\\\n",
    "    \\end{bmatrix}.\n",
    "    $$\n",
    "\n",
    "- Directional derivative functions\n",
    "\n",
    "    $$\n",
    "    D_{\\mathbf{u}} \\mathbf{f} (\\mathbf{x}) = \\begin{bmatrix}\n",
    "    D_{\\mathbf{u}} f_{1} (\\mathbf{x}) \\\\\n",
    "    \\vdots \\\\\n",
    "    D_{\\mathbf{u}} f_{m} (\\mathbf{x}) \\\\\n",
    "    \\end{bmatrix}.\n",
    "    $$\n",
    "\n",
    "- Jacobian matrix\n",
    "\n",
    "    $$\n",
    "    \\mathbf{J} \\mathbf{f} (\\mathbf{x}) = \\begin{bmatrix}\n",
    "    - & \\nabla^{T} f_{1} (\\mathbf{x}) & - \\\\\n",
    "    & \\vdots & \\\\\n",
    "    - & \\nabla^{T} f_{m} (\\mathbf{x}) & - \\\\\n",
    "    \\end{bmatrix} = \\begin{bmatrix}\n",
    "    \\frac{\\partial f_{1}}{x_{1}} (\\mathbf{x}) & \\dots & \\frac{\\partial f_{1}}{x_{n}} (\\mathbf{x}) \\\\\n",
    "    \\vdots & \\ddots & \\vdots \\\\\n",
    "    \\frac{\\partial f_{m}}{x_{1}} (\\mathbf{x}) & \\dots & \\frac{\\partial f_{m}}{x_{n}} (\\mathbf{x}) \\\\\n",
    "    \\end{bmatrix}\n",
    "    = \\begin{bmatrix}\n",
    "    | & & | \\\\\n",
    "    \\nabla f_{1} (\\mathbf{x}) & \\dots & \\nabla f_{m} (\\mathbf{x}) \\\\\n",
    "    | & & | \\\\\n",
    "    \\end{bmatrix}^{T}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350fcb0c-9586-4069-9ec0-eb6e2bf0f8ba",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Functional Derivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c3d2a1-8e6b-45ab-b731-01451a5f690b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Function of functions \n",
    "\n",
    "A function $f$ itself can be viewed as an infinite-dimensional vector \n",
    "\n",
    "$$\n",
    "D_{u} F [f] = \\lim_{h \\rightarrow 0} \\frac{F [f + h u] - F [f]}{h}\n",
    "$$\n",
    "\n",
    "Using a similar trick used in equation [](derivative), \n",
    "we can see that \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "D_{u} F [f] \n",
    "& = D_{u} F [f + \\epsilon u] \\Big|_{\\epsilon = 0}\n",
    "\\\\\n",
    "& = \\lim_{h \\rightarrow 0} \\frac{F [f + \\epsilon u + h u] - F [f + \\epsilon u]}{h} \\Big|_{\\epsilon = 0}\n",
    "\\\\\n",
    "& = \\lim_{h \\rightarrow 0} \\frac{F [f + (\\epsilon + h) u] - F [f + \\epsilon u]}{h} \\Big|_{\\epsilon = 0}\n",
    "\\\\\n",
    "& = \\frac{d}{d \\epsilon} F [f + \\epsilon u] \\Big|_{\\epsilon = 0}\n",
    "\\\\\n",
    "\\end{aligned}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
